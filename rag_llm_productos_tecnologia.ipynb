{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO0bOjudAX+bmBur1UMeLL0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/stefymojica/sample-rag-llm/blob/main/rag_llm_productos_tecnologia.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Modelo RAG - LLM con productos de tecnologia**"
      ],
      "metadata": {
        "id": "OJAazV-IBX9C"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bmuLG6Oeu3Oq",
        "outputId": "00a326dc-a1b8-400a-9e0d-04472ae3da34"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.10/dist-packages (3.2.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.5.2)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.44.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.66.5)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (2.5.0+cu121)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.13.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (0.24.7)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (10.4.0)\n",
            "Requirement already satisfied: numpy>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2024.6.1)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (4.12.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.4)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.9.11)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.19.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2024.8.30)\n"
          ]
        }
      ],
      "source": [
        "pip install sentence-transformers pandas scikit-learn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install torch transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rHGu49gdDufa",
        "outputId": "e89ad942-b7c5-4903-c3a6-534575b5218d"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.0+cu121)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.44.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.6.1)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.24.7)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM"
      ],
      "metadata": {
        "id": "YetgddbsxQJ2"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# class SimpleRag:\n",
        "#   def __init__(self):\n",
        "#     self.embedding_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "#     self.documents = []\n",
        "#     self.embeddings = None\n",
        "#     self.tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
        "#     self.model = AutoModelForCausalLM.from_pretrained(\"gpt2\")\n",
        "\n",
        "#   def add_documents(self, documents):\n",
        "#     self.documents.extend(documents)\n",
        "#     self.embeddings = self.embedding_model.encode(self.documents)\n",
        "\n",
        "#   def query(self,question,k=2):\n",
        "#     question_embedding = self.embedding_model.encode(question)\n",
        "#     similarities = cosine_similarity([question_embedding],self.embeddings)[0]\n",
        "#     top_k_indices = np.argsort(similarities)[-k:][::-1]\n",
        "#     result = []\n",
        "#     for i in top_k_indices:\n",
        "#       result.append({'document':self.documents[i], 'score':similarities[i]})\n",
        "#     return result\n",
        "\n",
        "#   def generate_text(self,question):\n",
        "#     retrieved_docs = self.query(question)\n",
        "#     context = \" \".join([doc['document'] for doc in retrieved_docs])\n",
        "#     prompt = f\"\"\"Context: {context}\n",
        "#     Question: {question}\n",
        "#     Answer:\"\"\"\n",
        "#     inputs = self.tokenizer(prompt, return_tensors=\"pt\")\n",
        "#     outputs = self.model.generate(**inputs, max_length=200)\n",
        "#     answer = self.tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "#     return answer\n"
      ],
      "metadata": {
        "id": "1WYKMa0zIiUO"
      },
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "class SimpleRag:\n",
        "    def __init__(self):\n",
        "        self.embedding_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "        self.documents = []\n",
        "        self.embeddings = None\n",
        "\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
        "        self.model = AutoModelForCausalLM.from_pretrained(\"gpt2\")\n",
        "\n",
        "    def add_documents(self, documents):\n",
        "        self.documents.extend(documents)\n",
        "        self.embeddings = self.embedding_model.encode(self.documents)\n",
        "\n",
        "    def query(self, question, k=2):\n",
        "        question_embedding = self.embedding_model.encode(question)\n",
        "        similarities = cosine_similarity([question_embedding], self.embeddings)[0]\n",
        "        top_k_indices = np.argsort(similarities)[-k:][::-1]\n",
        "        result = []\n",
        "        for i in top_k_indices:\n",
        "            result.append({'document': self.documents[i], 'score': similarities[i]})\n",
        "        return result\n",
        "\n",
        "    def generate_text(self, question):\n",
        "        retrieved_docs = self.query(question)\n",
        "        context = \"\\n\".join([doc['document'] for doc in retrieved_docs])\n",
        "        prompt = f\"\"\"\n",
        "        Basándote en el siguiente contexto, genera una respuesta concisa y clara.\n",
        "\n",
        "        Contexto:\n",
        "        {context}\n",
        "\n",
        "        Pregunta: {question}\n",
        "        Respuesta:\"\"\"\n",
        "\n",
        "        inputs = self.tokenizer(prompt, return_tensors=\"pt\", truncation=True, max_length=500)\n",
        "        try:\n",
        "            outputs = self.model.generate(\n",
        "                **inputs,\n",
        "                max_length=500,\n",
        "                num_return_sequences=1,\n",
        "                temperature=0.7,\n",
        "                top_p=0.95,\n",
        "                do_sample=True,\n",
        "                pad_token_id=self.tokenizer.eos_token_id,\n",
        "                no_repeat_ngram_size=3,\n",
        "                early_stopping=True\n",
        "            )\n",
        "\n",
        "            answer = self.tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "            answer = answer.split(\"Respuesta:\")[-1].strip()\n",
        "\n",
        "            return answer\n",
        "\n",
        "        except Exception as e:\n",
        "            return f\"Error generando respuesta: {str(e)}\"\n",
        "\n",
        "def main():\n",
        "    documents = [\n",
        "        \"iPhone 14 Pro: Smartphone de última generación con pantalla de 6.1 pulgadas, cámara de 48MP y chip A16 Bionic. Precio: $999\",\n",
        "        \"Samsung Galaxy S23: Teléfono Android con pantalla AMOLED de 6.1 pulgadas, cámara de 50MP y procesador Snapdragon 8. Precio: $799\",\n",
        "        \"MacBook Air M2: Laptop ultradelgada con chip M2, 8GB RAM, 256GB SSD y pantalla Retina de 13.6 pulgadas. Precio: $1199\",\n",
        "        \"Sony WH-1000XM5: Auriculares inalámbricos con cancelación de ruido, 30 horas de batería y audio de alta resolución. Precio: $399\",\n",
        "        \"Nintendo Switch OLED: Consola de videojuegos con pantalla OLED de 7 pulgadas, 64GB de almacenamiento y modo portátil. Precio: $349\",\n",
        "        \"iPad Air 2022: Tablet con chip M1, pantalla de 10.9 pulgadas, compatible con Apple Pencil y Magic Keyboard. Precio: $599\",\n",
        "        \"Dell XPS 15: Laptop para profesionales con Intel i7, 16GB RAM, 512GB SSD y pantalla 4K de 15.6 pulgadas. Precio: $1799\",\n",
        "        \"AirPods Pro 2: Auriculares TWS con cancelación activa de ruido, audio espacial y resistencia al agua IPX4. Precio: $249\",\n",
        "        \"PlayStation 5: Consola de nueva generación con SSD ultrarrápido, ray tracing y control DualSense. Precio: $499\",\n",
        "        \"Samsung QN90B: Smart TV QLED 4K de 65 pulgadas con tasa de refresco de 120Hz y HDR. Precio: $1999\"\n",
        "    ]\n",
        "\n",
        "    print(\"Inicializando RAG...\")\n",
        "    rag = SimpleRag()\n",
        "\n",
        "    print(\"Agregando documentos...\")\n",
        "    rag.add_documents(documents)\n",
        "\n",
        "    questions = [\n",
        "        \"tipos de laptop\"\n",
        "    ]\n",
        "\n",
        "    for question in questions:\n",
        "        print(f\"\\nPregunta: {question}\")\n",
        "\n",
        "        retrieved_docs = rag.query(question)\n",
        "        print(\"\\nDocumentos relevantes:\")\n",
        "        for doc in retrieved_docs:\n",
        "            print(f\"Score: {doc['score']:.4f} - {doc['document']}\")\n",
        "\n",
        "        result = rag.generate_text(question)\n",
        "        print(f\"\\nRespuesta generada: {result}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fRXAkobDjbqK",
        "outputId": "e01fc230-c405-4cfb-d1fb-e1934eec125c"
      },
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inicializando RAG...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Agregando documentos...\n",
            "\n",
            "Pregunta: tipos de laptop\n",
            "\n",
            "Documentos relevantes:\n",
            "Score: 0.4959 - Dell XPS 15: Laptop para profesionales con Intel i7, 16GB RAM, 512GB SSD y pantalla 4K de 15.6 pulgadas. Precio: $1799\n",
            "Score: 0.4392 - MacBook Air M2: Laptop ultradelgada con chip M2, 8GB RAM, 256GB SSD y pantalla Retina de 13.6 pulgadas. Precio: $1199\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:615: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Respuesta generada: piedra su puede entre con clara y con una con comunidad.\n",
            "Pregunta en la forma de novie:\n",
            "I am not a fan of the way the MacBook Pro is handled by the Intel i5, i7 and i9. I think that the MacBook is the better option because it uses the same processor and RAM as the MacBook.\n",
            "I believe that iMacs are better for the same reason. I'm not going to go into details about the iMac Pro because I'm sure that I won't get much information from my review.\n",
            "The iMac is great for the amount of RAM it has. I have a few of my MacBook Pro's on my desk. I like the fact that the Pro features a lot of RAM.\n",
            "One of the things that I think the MacBook Pros do well is the performance of the graphics cards. I would like to see the graphics card drivers for the i7-6700K.\n",
            "There are two kinds of cards in the iBook Pro. One is the XPS 14 GPU. The other is the NVIDIA GeForce GTX 1050M. I will try to give the i5 and i7 cards a try as well.\n",
            "If you have any questions, feel free to ask them on our forum.\n",
            "We will be updating this guide once the first one is published.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Sj9eqxmIkvb5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}